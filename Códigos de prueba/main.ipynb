{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1d8396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA disponible: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1.42G/1.42G [04:17<00:00, 5.93MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo medium listo en torch.float16\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------\n",
    "#-------------------------------------------------------------\n",
    "#-----------------CARGA DEL MODELO WHISPER--------------------\n",
    "#-------------------------------------------------------------\n",
    "#-------------------------------------------------------------\n",
    "#-------------------------------------------------------------\n",
    "\n",
    "import torch, whisper\n",
    "\n",
    "print(\"CUDA disponible:\", torch.cuda.is_available())\n",
    "\n",
    "# esto volverá a descargar medium de cero\n",
    "model = whisper.load_model(\"medium\", device=\"cpu\")\n",
    "\n",
    "# luego lo pasas a GPU en float16\n",
    "model = model.to(torch.device(\"cuda\"), dtype=torch.float16)\n",
    "\n",
    "print(\"Modelo medium listo en\", next(model.parameters()).dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070ebc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando Whisper medium en GPU…\n",
      "Modelo cargado en GPU con dtype: torch.float32\n",
      "Grabando 5s de audio…\n",
      "Grabación completada.\n",
      "Transcribiendo (español, fp32)…\n",
      "Texto reconocido:  Hola que tal, esta es la primera prueba\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------\n",
    "#-------------------------------------------------------------\n",
    "#------------Primera prueba, Transcribía lento----------------\n",
    "#-------------------------------------------------------------\n",
    "#-------------------------------------------------------------\n",
    "#-------------------------------------------------------------\n",
    "\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import whisper, torch, tempfile\n",
    "\n",
    "SAMPLERATE = 16000  # Hz\n",
    "DURATION   = 5      # segundos\n",
    "\n",
    "# 1) Cargar Whisper medium directamente en GPU (float32)\n",
    "print(\"Cargando Whisper medium en GPU…\")\n",
    "model = whisper.load_model(\"medium\", device=\"cuda\")\n",
    "print(\"Modelo cargado en GPU con dtype:\", next(model.parameters()).dtype)\n",
    "\n",
    "def grabar_y_transcribir():\n",
    "    print(f\"Grabando {DURATION}s de audio…\")\n",
    "    audio = sd.rec(int(SAMPLERATE * DURATION),\n",
    "    samplerate=SAMPLERATE, channels=1,dtype='int16')\n",
    "    sd.wait()\n",
    "    print(\"Grabación completada.\")\n",
    "\n",
    "    # Guardar en WAV temporal\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as f:\n",
    "        write(f.name, SAMPLERATE, audio)\n",
    "        print(\"Transcribiendo (español, fp32)…\")\n",
    "        result = model.transcribe(\n",
    "            f.name,\n",
    "            language=\"es\",   # omite detect_language\n",
    "            fp16=False       # fuerza float32 en el decodificador\n",
    "        )\n",
    "        print(\"Texto reconocido:\", result[\"text\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    grabar_y_transcribir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b8d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabando 5s de audio…\n",
      "Grabación completada.\n",
      "Transcribiendo (español, fp32)…\n",
      "Texto reconocido:  si yo quiero decir por ejemplo junta 1 30 grados a la derecha\n"
     ]
    }
   ],
   "source": [
    "'''grabar_y_transcribir()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca146c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo *small* para keyword‑spotting …\n",
      "Cargando modelo *medium* para comando …\n",
      "» Consumidor activo. Esperando la frase clave…\n",
      "» Productor de audio activo.\n",
      "(kws) hola. hola.\n",
      "(kws) hola. hola.\n",
      "(kws) hola. hola.\n",
      "(kws) hola. hola.\n",
      "(kws) hola. hola.\n",
      "(kws) hola. hola.\n",
      "(kws) hola.\n",
      "» Frase clave detectada → grabando comando…\n",
      "» Comando detectado → hola hola\n",
      "   (No se entendió ningún comando válido)\n",
      "(kws) no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no\n",
      "(kws) \n",
      "(kws) junta, junta, uno, tres.\n",
      "(kws) junta, uno, treinta junta, uno, treinta\n",
      "(kws) junta, 1-30 junta, 1-30\n",
      "(kws) junta 130 grados\n",
      "(kws) 1 riktor po evangelio\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 141\u001b[39m\n\u001b[32m    138\u001b[39m     consumer()\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 138\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m    137\u001b[39m     threading.Thread(target=producer, daemon=\u001b[38;5;28;01mTrue\u001b[39;00m).start()\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     \u001b[43mconsumer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 100\u001b[39m, in \u001b[36mconsumer\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m» Consumidor activo. Esperando la frase clave…\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     block = \u001b[43maudio_q\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.flatten()\n\u001b[32m    102\u001b[39m     \u001b[38;5;66;03m# ---------- Estado: IDLE ----------\u001b[39;00m\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m state == \u001b[33m\"\u001b[39m\u001b[33midle\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\queue.py:171\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout < \u001b[32m0\u001b[39m:\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must be a non-negative number\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------------------------------------\n",
    "#---Segunda prueba, Aquí ya se hizo una demo de un sistema de reconocimiento que se activa al decir \"hola\"--------------------\n",
    "#-----------------------------------------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import queue, threading, time, tempfile, os, re, difflib, collections\n",
    "import whisper, torch, unidecode, webrtcvad\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# ─── Parámetros globales ──────────────────────────────────────────────────────\n",
    "SAMPLERATE      = 16_000    # Hz\n",
    "BLOCK_SEC       = 2         # segundos por bloque de audio\n",
    "KWS_NBLK        = 2         # Nº de bloques concatenados para KWS (mejor contexto)\n",
    "TRIGGER_PHRASE  = \"hola\"    # frase de activación (sin tildes)\n",
    "TRIGGER_SIM_TH  = 0.85      # umbral de similitud para activar\n",
    "MAX_CMD_TIME    = 3         # s máximos para comando\n",
    "SILENCE_SEC     = 1         # parar si silencio prolongado ≥ 1 s\n",
    "SILENCE_LVL     = 0.05      # umbral RMS para “silencio”\n",
    "\n",
    "# ---- WebRTC‑VAD frame -----------------\n",
    "VAD_FRAME_MS    = 30\n",
    "VAD_FRAME_SAMP  = int(SAMPLERATE * VAD_FRAME_MS / 1000)   # 480 a 16 kHz\n",
    "# ---------------------------------------\n",
    "\n",
    "# ─── Cargar modelos Whisper ──────────────────────────────────────────────────\n",
    "print(\"Cargando modelo *small* para keyword‑spotting …\")\n",
    "model_kws = whisper.load_model(\"small\", device=\"cuda\")\n",
    "\n",
    "print(\"Cargando modelo *medium* para comando …\")\n",
    "model_cmd = whisper.load_model(\"medium\", device=\"cuda\")\n",
    "\n",
    "# ─── Simulador de transmisión serial ────────────────────────────────────────\n",
    "def send_serial_sim(msg: str):\n",
    "    \"\"\"Imita la escritura a un puerto serie mostrando la cadena en pantalla.\"\"\"\n",
    "    print(f\"[SERIAL] {msg}\")\n",
    "\n",
    "# ─── VAD basado en WebRTC ───────────────────────────────────────────────────\n",
    "vad = webrtcvad.Vad(2)   # agresividad 0–3\n",
    "\n",
    "def is_speech(block_f32: np.ndarray) -> bool:\n",
    "    \"\"\"True si alguna sub‑trama de 30 ms contiene voz.\"\"\"\n",
    "    pcm = (block_f32 * 32767).astype(np.int16)\n",
    "    bytes_pcm = pcm.tobytes()\n",
    "    for i in range(0, len(pcm), VAD_FRAME_SAMP):\n",
    "        frame = bytes_pcm[i*2 : (i+VAD_FRAME_SAMP)*2]\n",
    "        if len(frame) < VAD_FRAME_SAMP * 2:\n",
    "            break\n",
    "        if vad.is_speech(frame, SAMPLERATE):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# ─── Colas y estado ─────────────────────────────────────────────────────────\n",
    "audio_q = queue.Queue()\n",
    "state   = \"idle\"            # \"idle\" | \"waiting_cmd\"\n",
    "cmd_start_time = 0\n",
    "cmd_buffer: list[np.ndarray] = []\n",
    "kws_buffer = collections.deque(maxlen=KWS_NBLK)  # ventana deslizante para KWS\n",
    "\n",
    "# ─── Captura de audio (hilo productor) ──────────────────────────────────────\n",
    "def audio_callback(indata, frames, time_info, status):\n",
    "    audio_q.put(indata.copy())\n",
    "\n",
    "def producer():\n",
    "    with sd.InputStream(samplerate=SAMPLERATE,\n",
    "                        channels=1,\n",
    "                        blocksize=int(SAMPLERATE*BLOCK_SEC),\n",
    "                        dtype=\"float32\",\n",
    "                        callback=audio_callback):\n",
    "        print(\"» Productor de audio activo.\")\n",
    "        while True:\n",
    "            time.sleep(0.1)\n",
    "\n",
    "# ─── Transcripción con Whisper ──────────────────────────────────────────────\n",
    "def whisper_text(model, wav_f32):\n",
    "    tmp = tempfile.mktemp(suffix=\".wav\")\n",
    "    write(tmp, SAMPLERATE, (wav_f32*32767).astype(np.int16))\n",
    "    out = model.transcribe(tmp, language=\"es\", fp16=False)[\"text\"].lower().strip()\n",
    "    os.unlink(tmp)\n",
    "    return out\n",
    "\n",
    "# ─── Función helper: similitud con la frase clave ──────────────────────────\n",
    "def is_trigger(text):\n",
    "    return difflib.SequenceMatcher(None, text, TRIGGER_PHRASE).ratio() >= TRIGGER_SIM_TH\n",
    "\n",
    "# ─── Procesar y “enviar” comando ────────────────────────────────────────────\n",
    "def process_sentence(text):\n",
    "    clean = unidecode.unidecode(text)\n",
    "    m = re.search(r\"junta\\s+(\\d+).*?(-?\\d+)\\s*grados\", clean)\n",
    "    if m:\n",
    "        joint, angle = int(m.group(1)), int(m.group(2))\n",
    "        print(f\"→ Orden decodificada: J{joint}={angle}\")\n",
    "        send_serial_sim(f\"J{joint}:{angle}\")\n",
    "    else:\n",
    "        print(\"   (No se entendió ningún comando válido)\")\n",
    "\n",
    "# ─── Máquina de estados (hilo consumidor) ──────────────────────────────────\n",
    "def consumer():\n",
    "    global state, cmd_start_time, cmd_buffer\n",
    "    silent_blocks = 0\n",
    "    print(\"» Consumidor activo. Esperando la frase clave…\")\n",
    "\n",
    "    while True:\n",
    "        block = audio_q.get().flatten()\n",
    "\n",
    "        # ---------- Estado: IDLE ----------\n",
    "        if state == \"idle\":\n",
    "            if np.sqrt(np.mean(block**2)) < SILENCE_LVL or not is_speech(block):\n",
    "                continue\n",
    "            kws_buffer.append(block)\n",
    "            if len(kws_buffer) < KWS_NBLK:\n",
    "                continue\n",
    "            wav_kws = np.concatenate(kws_buffer, axis=0)\n",
    "            text_kws = whisper_text(model_kws, wav_kws)\n",
    "            print(\"(kws)\", text_kws)\n",
    "            if is_trigger(text_kws):\n",
    "                print(\"» Frase clave detectada → grabando comando…\")\n",
    "                state = \"waiting_cmd\"\n",
    "                cmd_start_time = time.time()\n",
    "                cmd_buffer = []\n",
    "                silent_blocks = 0\n",
    "\n",
    "        # ---------- Estado: WAITING_CMD ----------\n",
    "        elif state == \"waiting_cmd\":\n",
    "            cmd_buffer.append(block)\n",
    "            if np.sqrt(np.mean(block**2)) < SILENCE_LVL or not is_speech(block):\n",
    "                silent_blocks += 1\n",
    "            else:\n",
    "                silent_blocks = 0\n",
    "\n",
    "            if time.time() - cmd_start_time >= MAX_CMD_TIME or silent_blocks * BLOCK_SEC >= SILENCE_SEC:\n",
    "                wav_cmd = np.concatenate(cmd_buffer, axis=0)\n",
    "                text_cmd = whisper_text(model_cmd, wav_cmd)\n",
    "                print(\"» Comando detectado →\", text_cmd)\n",
    "                process_sentence(text_cmd)\n",
    "                state = \"idle\"\n",
    "                kws_buffer.clear()\n",
    "\n",
    "# ─── Main ───────────────────────────────────────────────────────────────────\n",
    "def main():\n",
    "    threading.Thread(target=producer, daemon=True).start()\n",
    "    consumer()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
